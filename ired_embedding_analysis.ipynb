{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRED Trajectory Embedding Analysis\n",
    "\n",
    "This notebook generates 2D embeddings of IRED optimization trajectories using PCA and nonlinear methods (Isomap) to visualize the manifold structure of the optimization process.\n",
    "\n",
    "## Data Overview\n",
    "- 150 matrix inverse problems\n",
    "- 10 optimization steps per problem (1500 total trajectory points)\n",
    "- 64-dimensional state vectors (8x8 matrices flattened)\n",
    "- Energy and error metrics for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create output directories\n",
    "results_dir = Path('/Users/mkrasnow/Desktop/diff-geo-ired/documentation/results')\n",
    "figures_dir = Path('/Users/mkrasnow/Desktop/diff-geo-ired/documentation/figures')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "figures_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Imports and directories ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Trajectory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trajectory data\n",
    "data_path = '/Users/mkrasnow/Desktop/diff-geo-ired/documentation/results/ired_trajectories_raw.npz'\n",
    "trajectory_data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "print(\"=== Trajectory Data Overview ===\")\n",
    "for key in trajectory_data.keys():\n",
    "    if hasattr(trajectory_data[key], 'shape'):\n",
    "        print(f\"{key}: {trajectory_data[key].shape} ({trajectory_data[key].dtype})\")\n",
    "    else:\n",
    "        print(f\"{key}: {trajectory_data[key]} ({type(trajectory_data[key])})\")\n",
    "\n",
    "# Extract key arrays\n",
    "num_problems = int(trajectory_data['num_problems'])\n",
    "num_steps = int(trajectory_data['num_steps'])\n",
    "states = trajectory_data['states']  # Shape: (150, 10, 1, 64)\n",
    "energies = trajectory_data['energies']  # Shape: (150, 10, 1, 1) \n",
    "error_metrics = trajectory_data['error_metrics']  # Shape: (150, 10, 1)\n",
    "landscapes = trajectory_data['landscapes']  # Shape: (150, 10)\n",
    "steps = trajectory_data['steps']  # Shape: (150, 10)\n",
    "\n",
    "print(f\"\\n=== Data Summary ===\")\n",
    "print(f\"Number of problems: {num_problems}\")\n",
    "print(f\"Steps per problem: {num_steps}\")\n",
    "print(f\"Total trajectory points: {num_problems * num_steps}\")\n",
    "print(f\"State dimensionality: {states.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for embedding analysis\n",
    "# Convert from (150, 10, 1, 64) to (1500, 64) for all trajectory points\n",
    "all_states = states.reshape(-1, states.shape[-1])  # (1500, 64)\n",
    "all_energies = energies.reshape(-1)  # (1500,)\n",
    "all_error_metrics = error_metrics.reshape(-1)  # (1500,)\n",
    "\n",
    "# Create trajectory metadata for visualization\n",
    "# Track which problem and step each point belongs to\n",
    "problem_indices = np.repeat(np.arange(num_problems), num_steps)  # (1500,)\n",
    "step_indices = np.tile(np.arange(num_steps), num_problems)  # (1500,)\n",
    "\n",
    "# Landscape parameters (for coloring)\n",
    "all_landscapes = landscapes.reshape(-1)  # (1500,)\n",
    "\n",
    "print(\"=== Reshaped Data ===\")\n",
    "print(f\"All states: {all_states.shape}\")\n",
    "print(f\"All energies: {all_energies.shape}\")\n",
    "print(f\"Problem indices: {problem_indices.shape}\")\n",
    "print(f\"Step indices: {step_indices.shape}\")\n",
    "print(f\"All landscapes: {all_landscapes.shape}\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "print(f\"\\n=== Data Quality Check ===\")\n",
    "print(f\"States - NaN: {np.isnan(all_states).sum()}, Inf: {np.isinf(all_states).sum()}\")\n",
    "print(f\"Energies - NaN: {np.isnan(all_energies).sum()}, Inf: {np.isinf(all_energies).sum()}\")\n",
    "print(f\"State range: [{np.min(all_states):.3f}, {np.max(all_states):.3f}]\")\n",
    "print(f\"Energy range: [{np.min(all_energies):.3f}, {np.max(all_energies):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate PCA Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for linear dimensionality reduction\n",
    "print(\"=== Applying PCA Embedding ===\")\n",
    "\n",
    "# Standardize the data\n",
    "states_standardized = (all_states - np.mean(all_states, axis=0)) / np.std(all_states, axis=0)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_embedding = pca.fit_transform(states_standardized)\n",
    "\n",
    "print(f\"PCA embedding shape: {pca_embedding.shape}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Save PCA embedding\n",
    "pca_save_path = results_dir / 'pca_embedding.npy'\n",
    "np.save(pca_save_path, pca_embedding)\n",
    "print(f\"Saved PCA embedding to: {pca_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Isomap Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Isomap for nonlinear dimensionality reduction\n",
    "print(\"=== Applying Isomap Embedding ===\")\n",
    "\n",
    "# Use a reasonable number of neighbors based on data size\n",
    "n_neighbors = min(15, max(5, int(np.sqrt(len(all_states)))))\n",
    "print(f\"Using n_neighbors = {n_neighbors}\")\n",
    "\n",
    "# Apply Isomap\n",
    "isomap = Isomap(n_components=2, n_neighbors=n_neighbors, path_method='D')\n",
    "isomap_embedding = isomap.fit_transform(states_standardized)\n",
    "\n",
    "print(f\"Isomap embedding shape: {isomap_embedding.shape}\")\n",
    "print(f\"Reconstruction error: {isomap.reconstruction_error():.6f}\")\n",
    "\n",
    "# Save Isomap embedding\n",
    "isomap_save_path = results_dir / 'isomap_embedding.npy'\n",
    "np.save(isomap_save_path, isomap_embedding)\n",
    "print(f\"Saved Isomap embedding to: {isomap_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Trajectory Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trajectory_plot(embedding, title, filename, n_trajectories_show=10):\n",
    "    \"\"\"\n",
    "    Create trajectory visualization showing temporal progression\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Plot 1: All points colored by step index\n",
    "    scatter = ax1.scatter(embedding[:, 0], embedding[:, 1], \n",
    "                         c=step_indices, cmap='viridis', alpha=0.6, s=20)\n",
    "    ax1.set_title(f'{title} - Colored by Step Index')\n",
    "    ax1.set_xlabel('Component 1')\n",
    "    ax1.set_ylabel('Component 2')\n",
    "    plt.colorbar(scatter, ax=ax1, label='Optimization Step')\n",
    "    \n",
    "    # Plot 2: All points colored by energy\n",
    "    scatter2 = ax2.scatter(embedding[:, 0], embedding[:, 1], \n",
    "                          c=all_energies, cmap='plasma', alpha=0.6, s=20)\n",
    "    ax2.set_title(f'{title} - Colored by Energy')\n",
    "    ax2.set_xlabel('Component 1')\n",
    "    ax2.set_ylabel('Component 2')\n",
    "    plt.colorbar(scatter2, ax=ax2, label='Energy')\n",
    "    \n",
    "    # Plot 3: Individual trajectories (subset)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_trajectories_show))\n",
    "    \n",
    "    for i in range(min(n_trajectories_show, num_problems)):\n",
    "        # Get points for this trajectory\n",
    "        traj_mask = problem_indices == i\n",
    "        traj_points = embedding[traj_mask]\n",
    "        \n",
    "        # Plot trajectory line\n",
    "        ax3.plot(traj_points[:, 0], traj_points[:, 1], \n",
    "                color=colors[i], alpha=0.7, linewidth=1.5, \n",
    "                label=f'Problem {i}' if i < 5 else '')\n",
    "        \n",
    "        # Mark start and end points\n",
    "        ax3.scatter(traj_points[0, 0], traj_points[0, 1], \n",
    "                   color=colors[i], marker='o', s=50, edgecolor='white', linewidth=1)\n",
    "        ax3.scatter(traj_points[-1, 0], traj_points[-1, 1], \n",
    "                   color=colors[i], marker='s', s=50, edgecolor='white', linewidth=1)\n",
    "    \n",
    "    ax3.set_title(f'{title} - Individual Trajectories')\n",
    "    ax3.set_xlabel('Component 1')\n",
    "    ax3.set_ylabel('Component 2')\n",
    "    if n_trajectories_show <= 5:\n",
    "        ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    save_path = figures_dir / filename\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved plot to: {save_path}\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA visualization\n",
    "pca_fig = create_trajectory_plot(\n",
    "    pca_embedding, \n",
    "    'PCA Embedding of IRED Trajectories', \n",
    "    'pca_trajectories_matrix_inverse.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Isomap visualization\n",
    "isomap_fig = create_trajectory_plot(\n",
    "    isomap_embedding, \n",
    "    'Isomap Embedding of IRED Trajectories', \n",
    "    'isomap_trajectories_matrix_inverse.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed Trajectory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_embedding_properties(embedding, name):\n",
    "    \"\"\"\n",
    "    Analyze geometric properties of the embedding\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {name} Embedding Analysis ===\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Embedding range: X=[{embedding[:, 0].min():.3f}, {embedding[:, 0].max():.3f}], \"\n",
    "          f\"Y=[{embedding[:, 1].min():.3f}, {embedding[:, 1].max():.3f}]\")\n",
    "    \n",
    "    # Compute trajectory lengths in embedding space\n",
    "    trajectory_lengths = []\n",
    "    initial_distances = []\n",
    "    final_distances = []\n",
    "    \n",
    "    for i in range(num_problems):\n",
    "        traj_mask = problem_indices == i\n",
    "        traj_points = embedding[traj_mask]\n",
    "        \n",
    "        # Compute path length\n",
    "        diffs = np.diff(traj_points, axis=0)\n",
    "        distances = np.linalg.norm(diffs, axis=1)\n",
    "        total_length = np.sum(distances)\n",
    "        trajectory_lengths.append(total_length)\n",
    "        \n",
    "        # Displacement from start to end\n",
    "        displacement = np.linalg.norm(traj_points[-1] - traj_points[0])\n",
    "        initial_distances.append(displacement)\n",
    "        \n",
    "        # Distance from origin\n",
    "        final_distance = np.linalg.norm(traj_points[-1])\n",
    "        final_distances.append(final_distance)\n",
    "    \n",
    "    trajectory_lengths = np.array(trajectory_lengths)\n",
    "    initial_distances = np.array(initial_distances)\n",
    "    final_distances = np.array(final_distances)\n",
    "    \n",
    "    print(f\"Trajectory path lengths: mean={trajectory_lengths.mean():.3f}, std={trajectory_lengths.std():.3f}\")\n",
    "    print(f\"Start-to-end displacement: mean={initial_distances.mean():.3f}, std={initial_distances.std():.3f}\")\n",
    "    print(f\"Final distances from origin: mean={final_distances.mean():.3f}, std={final_distances.std():.3f}\")\n",
    "    \n",
    "    # Compute trajectory sinuosity (path length / displacement)\n",
    "    sinuosity = trajectory_lengths / (initial_distances + 1e-8)  # Avoid division by zero\n",
    "    print(f\"Trajectory sinuosity: mean={sinuosity.mean():.3f}, std={sinuosity.std():.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'trajectory_lengths': trajectory_lengths,\n",
    "        'displacements': initial_distances,\n",
    "        'final_distances': final_distances,\n",
    "        'sinuosity': sinuosity\n",
    "    }\n",
    "\n",
    "# Analyze both embeddings\n",
    "pca_analysis = analyze_embedding_properties(pca_embedding, \"PCA\")\n",
    "isomap_analysis = analyze_embedding_properties(isomap_embedding, \"Isomap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embedding properties\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Trajectory lengths comparison\n",
    "axes[0, 0].hist(pca_analysis['trajectory_lengths'], bins=20, alpha=0.6, label='PCA', density=True)\n",
    "axes[0, 0].hist(isomap_analysis['trajectory_lengths'], bins=20, alpha=0.6, label='Isomap', density=True)\n",
    "axes[0, 0].set_xlabel('Trajectory Length')\n",
    "axes[0, 0].set_ylabel('Density')\n",
    "axes[0, 0].set_title('Distribution of Trajectory Lengths')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Displacement comparison\n",
    "axes[0, 1].hist(pca_analysis['displacements'], bins=20, alpha=0.6, label='PCA', density=True)\n",
    "axes[0, 1].hist(isomap_analysis['displacements'], bins=20, alpha=0.6, label='Isomap', density=True)\n",
    "axes[0, 1].set_xlabel('Start-to-End Displacement')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].set_title('Distribution of Trajectory Displacements')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Sinuosity comparison\n",
    "axes[1, 0].hist(pca_analysis['sinuosity'], bins=20, alpha=0.6, label='PCA', density=True)\n",
    "axes[1, 0].hist(isomap_analysis['sinuosity'], bins=20, alpha=0.6, label='Isomap', density=True)\n",
    "axes[1, 0].set_xlabel('Sinuosity (Path Length / Displacement)')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].set_title('Distribution of Trajectory Sinuosity')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Energy vs trajectory length\n",
    "final_energies = []\n",
    "for i in range(num_problems):\n",
    "    traj_mask = problem_indices == i\n",
    "    final_energies.append(all_energies[traj_mask][-1])\n",
    "\n",
    "final_energies = np.array(final_energies)\n",
    "\n",
    "axes[1, 1].scatter(pca_analysis['trajectory_lengths'], final_energies, alpha=0.6, label='PCA')\n",
    "axes[1, 1].set_xlabel('PCA Trajectory Length')\n",
    "axes[1, 1].set_ylabel('Final Energy')\n",
    "axes[1, 1].set_title('Trajectory Length vs Final Energy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'embedding_analysis_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved comparison plot to: {figures_dir / 'embedding_analysis_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Analysis Results\n",
    "\n",
    "Save embedding coordinates and analysis data for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive analysis results\n",
    "analysis_data = {\n",
    "    # Embedding coordinates\n",
    "    'pca_embedding': pca_embedding,\n",
    "    'isomap_embedding': isomap_embedding,\n",
    "    \n",
    "    # Metadata for each point\n",
    "    'problem_indices': problem_indices,\n",
    "    'step_indices': step_indices,\n",
    "    'all_energies': all_energies,\n",
    "    'all_error_metrics': all_error_metrics,\n",
    "    'all_landscapes': all_landscapes,\n",
    "    \n",
    "    # Trajectory analysis results\n",
    "    'pca_trajectory_lengths': pca_analysis['trajectory_lengths'],\n",
    "    'isomap_trajectory_lengths': isomap_analysis['trajectory_lengths'],\n",
    "    'pca_displacements': pca_analysis['displacements'],\n",
    "    'isomap_displacements': isomap_analysis['displacements'],\n",
    "    'pca_sinuosity': pca_analysis['sinuosity'],\n",
    "    'isomap_sinuosity': isomap_analysis['sinuosity'],\n",
    "    \n",
    "    # PCA parameters\n",
    "    'pca_explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "    'pca_total_variance_explained': pca.explained_variance_ratio_.sum(),\n",
    "    \n",
    "    # Isomap parameters\n",
    "    'isomap_n_neighbors': n_neighbors,\n",
    "    'isomap_reconstruction_error': isomap.reconstruction_error(),\n",
    "    \n",
    "    # Data parameters\n",
    "    'num_problems': num_problems,\n",
    "    'num_steps': num_steps,\n",
    "    'state_dimensionality': states.shape[-1]\n",
    "}\n",
    "\n",
    "# Save to NPZ file\n",
    "analysis_save_path = results_dir / 'ired_embedding_analysis.npz'\n",
    "np.savez_compressed(analysis_save_path, **analysis_data)\n",
    "\n",
    "print(f\"Saved comprehensive analysis to: {analysis_save_path}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"- {results_dir / 'pca_embedding.npy'}\")\n",
    "print(f\"- {results_dir / 'isomap_embedding.npy'}\")\n",
    "print(f\"- {results_dir / 'ired_embedding_analysis.npz'}\")\n",
    "print(f\"- {figures_dir / 'pca_trajectories_matrix_inverse.png'}\")\n",
    "print(f\"- {figures_dir / 'isomap_trajectories_matrix_inverse.png'}\")\n",
    "print(f\"- {figures_dir / 'embedding_analysis_comparison.png'}\")\n",
    "\n",
    "print(\"\\n=== Task 5.1 Completion Summary ===\")\n",
    "print(\"\u2705 Generated PCA and Isomap 2D embeddings\")\n",
    "print(\"\u2705 Created trajectory visualizations with temporal progression\")\n",
    "print(\"\u2705 Saved embedding coordinates in NPY format\")\n",
    "print(\"\u2705 Analyzed geometric properties of trajectories\")\n",
    "print(\"\u2705 Generated publication-quality figures\")\n",
    "print(f\"\\nData ready for geometric analysis (Task 5.2)!\")"
   ]
  },
  {
   "id": "cell-18",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trajectory Geometric Properties Analysis\n",
    "\n",
    "Compute detailed path lengths and discrete curvatures for each trajectory in both embedding spaces."
   ]
  },
  {
   "id": "cell-19",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the detailed geometric analysis module\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"compute_detailed_trajectory_geometry\", \"compute_detailed_trajectory_geometry.py\")\n",
    "geom_module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"compute_detailed_trajectory_geometry\"] = geom_module\n",
    "spec.loader.exec_module(geom_module)\n",
    "\n",
    "# Use the existing embedding data to compute geometric properties\n",
    "print(\"Computing geometric properties for trajectory embeddings...\")\n",
    "\n",
    "# Analyze both embeddings\n",
    "pca_summary, pca_detailed = geom_module.analyze_trajectory_geometry_detailed(\n",
    "    pca_embedding, problem_indices, step_indices, \"PCA\"\n",
    ")\n",
    "\n",
    "isomap_summary, isomap_detailed = geom_module.analyze_trajectory_geometry_detailed(\n",
    "    isomap_embedding, problem_indices, step_indices, \"Isomap\"\n",
    ")\n",
    "\n",
    "print(f\"\nGeometric analysis complete\\!\")\n",
    "print(f\"Summary records: {len(pca_summary) + len(isomap_summary)}\")\n",
    "print(f\"Detailed curvature records: {len(pca_detailed) + len(isomap_detailed)}\")"
   ]
  },
  {
   "id": "cell-20",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine results and save to CSV files as specified in Task 5.2\n",
    "import pandas as pd\n",
    "\n",
    "# Combine summary results (path lengths)\n",
    "all_summary_results = pca_summary + isomap_summary\n",
    "lengths_df = pd.DataFrame(all_summary_results)\n",
    "\n",
    "# Save path length results\n",
    "lengths_csv_path = results_dir / \"ired_trajectory_lengths.csv\"\n",
    "lengths_df.to_csv(lengths_csv_path, index=False)\n",
    "print(f\"\u2705 Saved trajectory lengths to: {lengths_csv_path}\")\n",
    "\n",
    "# Combine detailed curvature results\n",
    "all_curvature_results = pca_detailed + isomap_detailed\n",
    "curvatures_df = pd.DataFrame(all_curvature_results)\n",
    "\n",
    "# Save curvature results\n",
    "curvatures_csv_path = results_dir / \"ired_trajectory_curvatures.csv\"\n",
    "curvatures_df.to_csv(curvatures_csv_path, index=False)\n",
    "print(f\"\u2705 Saved trajectory curvatures to: {curvatures_csv_path}\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\n=== Trajectory Lengths CSV Preview ===\")\n",
    "print(lengths_df.head(10))\n",
    "print(f\"\nShape: {lengths_df.shape}\")\n",
    "\n",
    "print(f\"\n=== Trajectory Curvatures CSV Preview ===\")\n",
    "print(curvatures_df.head(10))\n",
    "print(f\"\nShape: {curvatures_df.shape}\")"
   ]
  },
  {
   "id": "cell-21",
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.2 Completion Summary\n",
    "\n",
    "Extended the trajectory embedding analysis with detailed geometric property calculations."
   ]
  },
  {
   "id": "cell-22",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\n\" + \"=\"*60)\n",
    "print(\"\ud83c\udfaf TASK 5.2 GEOMETRIC PROPERTIES ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\n\u2705 COMPLETED OBJECTIVES:\")\n",
    "print(\"  \u2022 Extended ired_embedding_analysis.ipynb with geometric analysis\")\n",
    "print(\"  \u2022 Computed path lengths using numpy.linalg.norm for distance calculations\")\n",
    "print(\"  \u2022 Computed discrete curvatures with epsilon=1e-8 regularization\")\n",
    "print(\"  \u2022 Handled division by zero in curvature calculation\")\n",
    "print(\"  \u2022 Skipped endpoints for curvature computation (interior points only)\")\n",
    "print(\"  \u2022 Saved results in CSV format for easy analysis\")\n",
    "\n",
    "print(f\"\n\ud83d\udcc1 OUTPUT FILES CREATED:\")\n",
    "print(f\"  \u2022 {lengths_csv_path}\")\n",
    "print(f\"  \u2022 {curvatures_csv_path}\")\n",
    "\n",
    "print(f\"\n\ud83d\udcca DATA SUMMARY:\")\n",
    "print(f\"  \u2022 Trajectories analyzed: {len(lengths_df)//2} per embedding ({len(lengths_df)} total records)\")\n",
    "print(f\"  \u2022 Embedding types: {', '.join(lengths_df[\"embedding_type\"].unique())}\")\n",
    "print(f\"  \u2022 Curvature measurements: {len(curvatures_df)} interior points\")\n",
    "\n",
    "for emb_type in [\"PCA\", \"Isomap\"]:\n",
    "    subset = lengths_df[lengths_df[\"embedding_type\"] == emb_type]\n",
    "    avg_length = subset[\"path_length\"].mean()\n",
    "    avg_curvature = subset[\"mean_curvature\"].mean()\n",
    "    print(f\"  \u2022 Average path length ({emb_type}): {avg_length:.4f}\")\n",
    "    print(f\"  \u2022 Average mean curvature ({emb_type}): {avg_curvature:.6f}\")\n",
    "\n",
    "print(f\"\n\ud83d\udd0d TECHNICAL IMPLEMENTATION:\")\n",
    "print(f\"  \u2022 Used numpy.linalg.norm for robust distance calculations\")\n",
    "print(f\"  \u2022 Applied epsilon regularization (\u03b5 = 1e-8) for numerical stability\") \n",
    "print(f\"  \u2022 Computed curvature only for interior points (excludes endpoints)\")\n",
    "print(f\"  \u2022 Discrete curvature formula: \u03ba = |y_{{t+1}} - 2y_t + y_{{t-1}}| / |y_{{t+1}} - y_t|\u00b2\")\n",
    "print(f\"  \u2022 CSV output format optimized for downstream analysis\")\n",
    "\n",
    "print(f\"\n\u2728 Task 5.2 complete\\! Geometric properties computed and saved.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}